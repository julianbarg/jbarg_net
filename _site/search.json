[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr. Julian Barg, climate disinformation research",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJulian Barg\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the OpenAI API to quickly code data in R\n\n\n\n\n\n\n\n\nMay 11, 2025\n\n\nJulian Barg\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "content/zbaracki_et_al_2021.html",
    "href": "content/zbaracki_et_al_2021.html",
    "title": "Zbaracki et al. (2021)",
    "section": "",
    "text": "Zbaracki, Mark J., Watkiss, Lee, McAlpine, Cameron and Barg, Julian (2021), “Truth, Beauty, and Justice in Models of Social Action”, Beckman, Christine M. (Ed.) Carnegie goes to California: Advancing and Celebrating the Work of James G. March (Research in the Sociology of Organizations, Vol. 76), Emerald Publishing Limited, Bingley, pp. 159-177. https://www.doi.org/10.1108/S0733-558X20210000076007\nThis author accepted manuscript is deposited under a Creative Commons Attribution Non-commercial 4.0 International (CC BY-NC) licence. This means that anyone may distribute, adapt, and build upon the work for non-commercial purposes, subject to full attribution. If you wish to use this manuscript for commercial purposes, please contact permissions@emerald.com."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/openai_r/index.html",
    "href": "posts/openai_r/index.html",
    "title": "Using the OpenAI API to quickly code data in R",
    "section": "",
    "text": "Every time I want to quickly bash out a command to code some data with ChatGPT in R, I stumble. Not that it is very difficult, it is just a very different workflow compared to the stuff I usually do, and I have to look it up every time. As a result, I am no longer in the flow.\nThe easiest way to interact with the OpenAI API, hands down, is to use the official python package. Yes, you could use curl or the R equivalent, but in practice many of the best features, such as structured outputs, are only available when using the python package, or the python implementation is more feature complete or easier to use.\nSince r-reticulate provides an interface between R and python, we can also take full advantage of the native python package when working in R. It plugs right into your regular workflow. First we initiate reticulate and grab some example data.\n\nlibrary(reticulate)\nlibrary(tidyverse)\nlibrary(janeaustenr)\ndata(\"emma\")\nglimpse(emma)\n\n chr [1:16235] \"EMMA\" \"\" \"By Jane Austen\" \"\" \"\" \"\" \"\" \"VOLUME I\" \"\" \"\" \"\" ...\n\n\nNext we switch over to R and set up the function for coding our text data. We could get fancy and accept role and task etc. as function arguments, but that should generally not be necessary.\n\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nimport json\n\nclient = OpenAI()\ndef code_male_female(line, model_, seed_ = 321):\n  role = \"\"\"\n  You are a graduate research assistants assisting us with our research project \n  on Jane Austen. Count the number of female and male characters per line.\n  \"\"\"\n  system_role = {\"role\": \"system\", \"content\": role}\n\n  task = f\"\"\"\n  Next, we will send you one line to analyze.\n  \n  {line}\n  \"\"\"\n  prompt_json = {\n    \"role\": \"user\", \n    \"content\": [\n      {\n        \"type\": \"text\", \n        \"text\": task\n      }\n    ]\n  }\n  messages_ = [\n    system_role, \n    prompt_json\n  ]\n  Certainty = Literal[\n    \"very certain\", \"certain\", \"neutral\", \"uncertain\", \"very uncertain\"\n    ]\n  class CodingResponse(BaseModel):\n    male: int = Field()\n    female: int = Field()\n    certainty: Certainty\n    \n  response = client.beta.chat.completions.parse(\n    model = model_,\n    messages = messages_,\n    response_format = CodingResponse\n  )\n  return json.loads(response.choices[0].message.content)\n  \ntest = code_male_female(\"This is just a text\", \"gpt-4o-mini\")\nprint(test)\n\n{'male': 0, 'female': 0, 'certainty': 'very certain'}\n\n\nNow we can conveniently apply this function to our Jane Austen sample within R.\n\ncode_partial &lt;- partial(py$code_male_female, model_ = \"gpt-4o-mini\")\nresults &lt;- map(emma[1:20], code_partial, .progress = T)\n\n ■■■■■■■                           20% |  ETA: 14s\n\n\n ■■■■■■■■■■■                       35% |  ETA: 12s\n\n\n ■■■■■■■■■■■■■■■■                  50% |  ETA:  9s\n\n\n ■■■■■■■■■■■■■■■■■■■■■             65% |  ETA:  6s\n\n\n ■■■■■■■■■■■■■■■■■■■■■■■■■■■       85% |  ETA:  3s\n\nbind_rows(results)\n\n# A tibble: 20 × 3\n    male female certainty   \n   &lt;int&gt;  &lt;int&gt; &lt;chr&gt;       \n 1     0      1 very certain\n 2     0      0 very certain\n 3     0      0 very certain\n 4     0      0 very certain\n 5     0      0 neutral     \n 6     0      0 certain     \n 7     0      0 neutral     \n 8     0      0 very certain\n 9     0      0 very certain\n10     0      0 very certain\n11     0      0 very certain\n12     0      0 very certain\n13     0      0 very certain\n14     0      0 neutral     \n15     0      1 very certain\n16     0      0 very certain\n17     0      0 very certain\n18     0      0 very certain\n19     0      0 very certain\n20     0      1 very certain"
  }
]