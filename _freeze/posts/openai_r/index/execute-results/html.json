{
  "hash": "a983abb85d66d62337a1bf38dd9ece8c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using the OpenAI API to quickly code data in R\"\ndate: 2025-05-11\n---\n\nEvery time I want to quickly bash out a command to code some data with ChatGPT\nin R, I stumble. Not that it is very difficult, it is just a very different \nworkflow compared to the stuff I usually do, and I have to look it up every \ntime. As a result, I am no longer in the flow.\n\nThe easiest way to interact with the OpenAI API, hands down, is to use the \nofficial python package. Yes, you could use curl or the R equivalent, but in \npractice many of the best features, such as structured outputs, are only \navailable when using the python package, or the python implementation is more \nfeature complete or easier to use.\n\nSince r-reticulate provides an interface between R and python, we can also take\nfull advantage of the native python package when working in R. It plugs right \ninto your regular workflow. First we initiate reticulate and grab some example\ndata.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(tidyverse)\nlibrary(janeaustenr)\ndata(\"emma\")\nglimpse(emma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n chr [1:16235] \"EMMA\" \"\" \"By Jane Austen\" \"\" \"\" \"\" \"\" \"VOLUME I\" \"\" \"\" \"\" ...\n```\n\n\n:::\n:::\n\n\nNext we switch over to R and set up the function for coding our text data. We\ncould get fancy and accept role and task etc. as function arguments, but that\nshould generally not be necessary.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nimport json\n\nclient = OpenAI()\ndef code_male_female(line, model_, seed_ = 321):\n  role = \"\"\"\n  You are a graduate research assistants assisting us with our research project \n  on Jane Austen. Count the number of female and male characters per line.\n  \"\"\"\n  system_role = {\"role\": \"system\", \"content\": role}\n\n  task = f\"\"\"\n  Next, we will send you one line to analyze.\n  \n  {line}\n  \"\"\"\n  prompt_json = {\n    \"role\": \"user\", \n    \"content\": [\n      {\n        \"type\": \"text\", \n        \"text\": task\n      }\n    ]\n  }\n  messages_ = [\n    system_role, \n    prompt_json\n  ]\n  Certainty = Literal[\n    \"very certain\", \"certain\", \"neutral\", \"uncertain\", \"very uncertain\"\n    ]\n  class CodingResponse(BaseModel):\n    male: int = Field()\n    female: int = Field()\n    certainty: Certainty\n    \n  response = client.beta.chat.completions.parse(\n    model = model_,\n    messages = messages_,\n    response_format = CodingResponse\n  )\n  return json.loads(response.choices[0].message.content)\n  \ntest = code_male_female(\"This is just a text\", \"gpt-4o-mini\")\nprint(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{'male': 0, 'female': 0, 'certainty': 'very certain'}\n```\n\n\n:::\n:::\n\n\nNow we can conveniently apply this function to our Jane Austen sample within R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncode_partial <- partial(py$code_male_female, model_ = \"gpt-4o-mini\")\nresults <- map(emma[1:20], code_partial, .progress = T)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n ■■■■■■■                           20% |  ETA: 14s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n ■■■■■■■■■■■                       35% |  ETA: 12s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n ■■■■■■■■■■■■■■■■                  50% |  ETA:  9s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n ■■■■■■■■■■■■■■■■■■■■■             65% |  ETA:  6s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n ■■■■■■■■■■■■■■■■■■■■■■■■■■■       85% |  ETA:  3s\n```\n\n\n:::\n\n```{.r .cell-code}\nbind_rows(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n    male female certainty   \n   <int>  <int> <chr>       \n 1     0      1 very certain\n 2     0      0 very certain\n 3     0      0 very certain\n 4     0      0 very certain\n 5     0      0 neutral     \n 6     0      0 certain     \n 7     0      0 neutral     \n 8     0      0 very certain\n 9     0      0 very certain\n10     0      0 very certain\n11     0      0 very certain\n12     0      0 very certain\n13     0      0 very certain\n14     0      0 neutral     \n15     0      1 very certain\n16     0      0 very certain\n17     0      0 very certain\n18     0      0 very certain\n19     0      0 very certain\n20     0      1 very certain\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}